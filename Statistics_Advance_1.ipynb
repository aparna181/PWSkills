{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Advance - 1"
      ],
      "metadata": {
        "id": "w3Hv6v6B1pLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a random variable in probability theory?\n",
        "   - A set of possible values from a random experiment.\n",
        "   - ex- tossing a coin:experiment is random , outcomes will be random variable."
      ],
      "metadata": {
        "id": "q-usS4eq1roU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the types of random variables?\n",
        "   - There are two types of random variable : (a) Discrete random variable and (b) Continous random variable"
      ],
      "metadata": {
        "id": "uEwaoN2u3sG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the difference between discrete and continuous distributions?\n",
        "   - Discrete random variable: Takes on a countable number of distinct values. The value often come from counting something.\n",
        "   - Continous random variable: Take on any value with in an interval or range. The values come from measuring something."
      ],
      "metadata": {
        "id": "UiLOulD_4GBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What are probability distribution functions (PDF)?\n",
        "   - PDF describes how probabilities are distributed over values. Mostly there are two types.\n",
        "   - (a) For discrete random variables (like the outcome of a die roll), the PDF is called the Probability Mass Function (PMF). It assigns a probability to each possible value.\n",
        "   - (b) For continuous random variables (like height, temperature), the PDF is a continuous function that describes the relative likelihood of the variable falling within a given interval. You can't assign a probability to an exact value."
      ],
      "metadata": {
        "id": "Tv7US5LA46vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "  - Definition: For a continuous random variable, the PDF, describes the likelihood of the variable taking on a specific value. For a discrete random variable, it’s called a probability mass function (PMF) and gives the probability of exact values.\n",
        "      - Purpose: It shows the relative likelihood of outcomes at specific points.\n",
        "  - Cumulative Distribution Function (CDF):Definition: The CDF,  gives the probability that a random variable  is less than or equal to a specific value .\n",
        "       - Purpose: It describes the cumulative probability up to a certain point.\n",
        "       \n",
        "       \n",
        "   - Key Differences:\n",
        "        - Nature:PDF/PMF: Describes the probability density (continuous) or exact probability (discrete) at a specific value.CDF: Describes the cumulative probability up to a value.\n",
        "        - Output:PDF: Outputs a density (not a probability for continuous variables) or a probability (for discrete variables).CDF: Outputs a probability (between 0 and 1).\n",
        "        - Visualization:PDF: A curve (continuous) or histogram (discrete) showing likelihoods.CDF: A non-decreasing function, often S-shaped, showing cumulative probabilitie"
      ],
      "metadata": {
        "id": "20dTeifD6YrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is a discrete uniform distribution?\n",
        "   - In a discrete uniform distribution the outcomes are discrete and have the same probability.\n",
        "   - ex: rollinng a dice, tossing a coin"
      ],
      "metadata": {
        "id": "CGD_PtVnARj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What are the key properties of a Bernoulli distribution?\n",
        "   - A Bernoulli distribution is the simplest type of probability distribution, used when there are only two possible outcomes: success (1) and failure (0).\n",
        "      - Only Two Outcomes: The random variable X takes only two values:\n",
        "         X=1 (success) and X=0 (failure)\n",
        "      - NO. of trials should be should be finite\n",
        "      - Each trial should be independent.\n",
        "      - Probability of each output should be same in every trial.\n",
        "      - Parameter: p : p is the probability of success(x=1) and 1-p is the probability of failure(x=0)\n",
        "      - Mean (Expected Value) : E(X)= p\n",
        "      - Variance: p(1-p)\n",
        "      - The values of X lie in the set {0,1}."
      ],
      "metadata": {
        "id": "0GOts2umAr6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the binomial distribution, and how is it used in probability?\n",
        "    - The Binomial Distribution is a type of discrete probability distribution that describes the number of successes in a fixed number of independent trials, where each trial has only two outcomes: success or failure.\n",
        "    - Binomial Distribution is the 'n' Bernoulli trial.\n",
        "    - Use:\n",
        "        - You repeat the same experiment multiple times.\n",
        "        - Each trial has only two outcomes (success or failure).\n",
        "        - Each trial is independent.\n",
        "        - The probability of success stays the same in each trial.\n",
        "\n"
      ],
      "metadata": {
        "id": "emKqOlXNCcXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the Poisson distribution and where is it applied?\n",
        "    - The poisson distribution is discrete probability distribution that describe the no. of events that occur within a fixed interval of time or space given a known average rate of occurance.\n",
        "    - The Poisson distribution is used in real-world situations where we count how often something happens in a time period or space, such as:\n",
        "       - Customer service:Number of phone calls received in an hour.\n",
        "       - Traffic flow:Number of cars passing a checkpoint in 10 minutes.\n",
        "       - Healthcare:Number of patient arrivals at a hospital per day\n",
        "       - Manufacturing:Number of defects found on a production line.\n",
        "       - Website analysis:Number of hits or clicks on a website per minute.\n",
        "\n"
      ],
      "metadata": {
        "id": "GZKq2vOqDBFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is a continuous uniform distribution?\n",
        "    - It is a distribution that has infinite no. of values defined in a specified range/bound.\n",
        "    "
      ],
      "metadata": {
        "id": "aABvYvqNEVVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What are the characteristics of a normal distribution/\n",
        "    - Symmetrical about mean: Left side of the curve is a mirror image of teh right\n",
        "    - Mean=Meadian=Mode : All are located at the center of the distribution\n",
        "    - skewness = 0\n",
        "    - Emperical rule(68-95-99.7% rule )\n",
        "    - Bell shaped curve\n",
        "    - It simplifies analysis, especially in inferential statistics."
      ],
      "metadata": {
        "id": "70_zoIsfEoNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the standard normal distribution, and why is it important?\n",
        "  - The Standard Normal Distribution is a special type of normal distribution (also called the Z-distribution) where: mean(average) = 0 and standard deviation= 1.\n",
        "  - Simplifies probability calculations using Z-tables.\n",
        "  - It allows comparison between different datasets with mean = 0.\n",
        "  "
      ],
      "metadata": {
        "id": "wzTi0f0IFaJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "   - The Central Limit Theorem (CLT) states that: When we take a large number of random samples from any population (no matter its original shape), the distribution of the sample means will approximate a normal distribution, as the sample size increases.\n",
        "       - Allows Use of Normal Distribution: CLT lets us use the normal distribution even if the data is not normally distributed, as long as the sample size is large.\n",
        "       - Foundation for Confidence Intervals: It helps build confidence intervals for estimating population parameters like mean or proportion.\n",
        "       \n",
        "       - Basis for Hypothesis Testing: Most statistical tests (Z-test, t-test) assume sample means are normally distributed due to CLT\n",
        "       - Makes Inference Possible: It enables us to make predictions and draw conclusions about the entire population using just a sample.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E9eECuOwGbOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "    - The Central Limit Theorem (CLT) is an important concept in statistics that explains the connection between sample data and the normal distribution. It states that if we take many random samples from any population, and the sample size is large enough (usually 30 or more), the average of those samples will form a normal (bell-shaped) distribution, even if the original population is not normally distributed. This means we can use the normal distribution to make predictions, calculate probabilities, and perform hypothesis testing, even when working with data that is not perfectly shaped. The CLT makes it possible to apply powerful statistical tools to real-world data."
      ],
      "metadata": {
        "id": "en9fU-4pHYrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the application of Z statistics in hypothesis testing?\n",
        "   - Z-statistics is used in hypothesis testing to determine whether there is a significant difference between sample data and the population data when the population standard deviation is known. It helps test claims or assumptions (hypotheses) about a population mean or proportion. In this process, we calculate a Z-score, which tells us how far the sample result is from the population mean in terms of standard deviations. By comparing the Z-score to a critical value from the Z-table, we can decide whether to accept or reject the null hypothesis. Z-tests are especially useful when the sample size is large (n ≥ 30) and the data follows a normal distribution or approximates it due to the Central Limit Theorem."
      ],
      "metadata": {
        "id": "LM8EXU4tH81X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How do you calculate a Z-score, and what does it represent?\n",
        "    - A Z-score is a value that tells us how many standard deviations a data point is from the mean. It is calculated using the formula:\n",
        "                    \n",
        "                    Z= (X−μ)/σ\n",
        "\n",
        "       where X is the data point, μ is the population mean, and σ is the population standard deviation.\n",
        "       \n",
        "    - The Z-score helps us understand whether a value is above or below the average, and by how much. For example, a Z-score of +2 means the value is 2 standard deviations above the mean, while a Z-score of –1.5 means it is 1.5 standard deviations below the mean. Z-scores are useful in comparing values from different datasets and in hypothesis testing using the standard normal distribution.             \n",
        "​\n"
      ],
      "metadata": {
        "id": "DRe6pckUIPth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What are point estimates and interval estimates in statistics?\n",
        "   - A point estimate is a single value that is used to estimate the true value of a population parameter.\n",
        "   - A interval estimate is a range of values used to estimate the unknown population paramater using sample."
      ],
      "metadata": {
        "id": "TDbEFzVDI3FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the significance of confidence intervals in statistical analysis?\n",
        "    - Confidence intervals are important in statistical analysis because they give us a range of values within which we believe the true population parameter (like the mean or proportion) lies. Instead of giving just one estimate from a sample, a confidence interval provides both a lower and upper limit, along with a confidence level (usually 95% or 99%). For example, if we say the average height is between 160 cm and 170 cm with 95% confidence, it means we are 95% sure that the actual population average falls within that range. Confidence intervals help us understand the accuracy and reliability of our estimates and are widely used in research, surveys, and decision-making."
      ],
      "metadata": {
        "id": "i4uOyJu5JcF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What is the relationship between a Z-score and a confidence interval?\n",
        "   - A Z-score is used to calculate a confidence interval when the population standard deviation is known. It helps determine how far the interval should extend from the sample mean based on the desired confidence level (e.g., 95% or 99%). Higher confidence levels use larger Z-scores, resulting in wider intervals."
      ],
      "metadata": {
        "id": "WdBMSRREJmuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How are Z-scores used to compare different distributions?\n",
        "    - Z-scores are used to compare different distributions by converting values from each distribution into a standardized form. This allows us to see how far each value is from its own mean in terms of standard deviations. Since Z-scores remove the units and scale of the original data, we can directly compare values from different datasets, even if they have different means and standard deviations."
      ],
      "metadata": {
        "id": "ChLxPI4iJwR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What are the assumptions for applying the Central Limit Theorem?\n",
        "    - The data should be collected through random sampling from the population. The no. of samples should be large.\n",
        "    - Each sample should be independent, meaning one observation does not influence another.\n",
        "    - The sample size should be large (usually n ≥ 30). If the population is already normally distributed, smaller samples may still work"
      ],
      "metadata": {
        "id": "NHAMwgi1J4r4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What is the concept of expected value in a probability distribution?\n",
        "    - The expected value is the average outcome you would expect if an experiment or random event is repeated many times. It is a key concept in probability that tells us the long-term average result of a random variable.\n",
        "    - The expected value is like the weighted average — it tells you what you can expect to happen on average over time."
      ],
      "metadata": {
        "id": "fherzSjBKg4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "   - A probability distribution shows all possible values a random variable can take and the probabilities of each value happening. The expected outcome (or expected value) is calculated using this distribution — it is the weighted average of all possible values, where each value is multiplied by its probability. So, the probability distribution tells us the likelihood of different results, and the expected value gives us the average result we can expect if the random event is repeated many times.\n",
        "\n"
      ],
      "metadata": {
        "id": "4ePtNu33K1-R"
      }
    }
  ]
}